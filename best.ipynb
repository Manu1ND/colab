{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Manu1ND/colab/blob/main/best.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "pip uninstall opencv-python-headless==4.5.5.62\n",
        "pip install opencv-python-headless==4.5.2.52\n",
        "pip install gdown\n",
        "apt-get install zip unzip\n",
        "'''"
      ],
      "metadata": {
        "id": "hL4IiNdt31u5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01U81VYgNCXo"
      },
      "source": [
        "# Specs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1i5YVreV6Omh",
        "outputId": "cda29bc9-46d2-437e-9539-0838dfb6c854"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Feb 26 08:11:56 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   71C    P8    32W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "  !nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8b_9-qkA5mKS",
        "outputId": "2c77469b-88c0-47e5-aed7-1824a9497539"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gputil in /usr/local/lib/python3.7/dist-packages (1.4.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.7/dist-packages (0.5.1)\n",
            "Gen RAM Free: 12.4 GB  | Proc size: 141.0 MB\n",
            "GPU RAM Free: 11441MB | Used: 0MB | Util   0% | Total 11441MB\n"
          ]
        }
      ],
      "source": [
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isnâ€™t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        " process = psutil.Process(os.getpid())\n",
        " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "QmI6XenmMp-X"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6lbrhPsboa7"
      },
      "source": [
        "# Import dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "bUQ-PWSVzAvt"
      },
      "outputs": [],
      "source": [
        "''' !pip install --upgrade gupload\n",
        "# from pydrive.auth import GoogleAuth\n",
        "from google.colab import auth\n",
        "auth.authenticate_user() '''\n",
        "\n",
        "# Run below two lines in terminal\n",
        "''' !pip uninstall opencv-python-headless==4.5.5.62\n",
        "!pip install opencv-python-headless==4.5.2.52 '''\n",
        "!pip install fastai -q --upgrade\n",
        "!pip install --upgrade albumentations\n",
        "from fastai.vision.all import *\n",
        "import gdown\n",
        "import os\n",
        "''' \n",
        "from google.colab import output\n",
        "output.clear() '''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "7ootEVMhywQs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61e73c03-07bc-45fa-d280-78544885bc13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.10.0+cu111\n"
          ]
        }
      ],
      "source": [
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgifIBJBdj2A"
      },
      "source": [
        "# Download Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "VLAViCl9zle5"
      },
      "outputs": [],
      "source": [
        "gdown.download('https://drive.google.com/u/1/uc?id=1PsX8ULvWg-peKtUduyTqkyxfxXoom13S', './owl.zip', quiet=False)\n",
        "!unzip ./owl.zip\n",
        "!rm ./owl.zip\n",
        "\n",
        "''' output.clear() '''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9zFwG9ibdAP"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "VPQ3fgo-i3l2"
      },
      "outputs": [],
      "source": [
        "seed = 1000\n",
        "\n",
        "def seed_everything(seed = seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "seed_everything()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "UiCDyGMoJhwY"
      },
      "outputs": [],
      "source": [
        "path = Path('./Dataset_OWL_COD10K_v3/')\n",
        "train_images = path/'Train/Image'\n",
        "train_labels = path/'Train/GT'\n",
        "test_name = \"Test\"\n",
        "test_images = path/test_name/'Image'\n",
        "test_labels = path/test_name/'GT'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "s6WddT_XopB9"
      },
      "outputs": [],
      "source": [
        "def get_y_fn(x): \n",
        "  return Path(str(x).replace(\"Image\",\"GT\").replace(\".jpg\",\".png\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "1XN5GnhJg2Nz"
      },
      "outputs": [],
      "source": [
        "def ParentSplitter(x):\n",
        "    return Path(x).parent.name==test_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iRg6ffySjJ63",
        "outputId": "1bc18865-0003-42a8-ba02-545d07132f07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'background': 0, 'owl': 1}\n"
          ]
        }
      ],
      "source": [
        "codes = ['background','owl']\n",
        "name2id = {v:k for k,v in enumerate(codes)}\n",
        "print(name2id)\n",
        "void_code = name2id['owl']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "_CswkPGyoiIA"
      },
      "outputs": [],
      "source": [
        "def foreground_acc(input, target):\n",
        "    target = cast(target.squeeze(1), TensorBase)\n",
        "    mask = target != void_code\n",
        "    return (input.argmax(dim=1)[mask]==target[mask]).float().mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "zVLpKYNZQZAP"
      },
      "outputs": [],
      "source": [
        "from albumentations import (\n",
        "    Compose,\n",
        "    \n",
        "    # Pixel\n",
        "    HueSaturationValue,\n",
        "    Posterize,\n",
        "    RandomSunFlare,\n",
        "\n",
        "    # Spatial\n",
        "    GridDistortion,\n",
        "    HorizontalFlip,\n",
        "    Perspective,\n",
        "    SafeRotate\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "BrlqRf00Qadm"
      },
      "outputs": [],
      "source": [
        "class SegmentationAlbumentationsTransform(ItemTransform):\n",
        "    split_idx = 0\n",
        "    def __init__(self, aug): \n",
        "        self.aug = aug\n",
        "    def encodes(self, x):\n",
        "        img,mask = x\n",
        "        aug = self.aug(image=np.array(img), mask=np.array(mask))\n",
        "        return PILImage.create(aug[\"image\"]), PILMask.create(aug[\"mask\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "9OcwhMJgQcPq"
      },
      "outputs": [],
      "source": [
        "class TargetMaskConvertTransform(ItemTransform):\n",
        "    def __init__(self): \n",
        "        pass\n",
        "    def encodes(self, x):\n",
        "        img,mask = x\n",
        "        mask = np.array(mask)\n",
        "        mask[mask==255]=1\n",
        "        mask = PILMask.create(mask)\n",
        "        return img, mask"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gsbtw3nugokf"
      },
      "source": [
        "# Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "2-u_staXFjZB"
      },
      "outputs": [],
      "source": [
        "bs = 8\n",
        "splitter = RandomSplitter(valid_pct=0.2, seed=seed)\n",
        "item_tfms = [Resize((512, 512), method=ResizeMethod.Crop), TargetMaskConvertTransform()]\n",
        "batch_tfms = [HueSaturationValue(), Posterize(), RandomSunFlare(), GridDistortion(), HorizontalFlip(), Perspective(), SafeRotate()]\n",
        "arch = resnet50\n",
        "pretrained = True\n",
        "metrics = [foreground_acc, Dice(), JaccardCoeff()]\n",
        "act_cls = Mish\n",
        "self_attention = True\n",
        "lr = 1e-3\n",
        "wd = 1e-1\n",
        "epochs = 200"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "jZEqOLA_XUTp"
      },
      "outputs": [],
      "source": [
        "monitor_training = \"valid_loss\"\n",
        "comp_training = np.less\n",
        "\n",
        "monitor_evaluating = \"dice\"\n",
        "comp_evaluating = np.greater\n",
        "\n",
        "patience = 50"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transformPipeline = Compose(batch_tfms, p=1)\n",
        "transformPipeline = SegmentationAlbumentationsTransform(transformPipeline)\n",
        "item_tfms.append(transformPipeline)"
      ],
      "metadata": {
        "id": "UmcEEiYh3I4W"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callbacksFitBeforeUnfreeze = [\n",
        "    ShowGraphCallback(),\n",
        "    EarlyStoppingCallback(monitor = monitor_training, comp = comp_training, patience = patience),\n",
        "    SaveModelCallback(monitor = monitor_training, comp = comp_training, every_epoch = False, fname = \"Camonet_Best\")  \n",
        "]"
      ],
      "metadata": {
        "id": "jnUSpGdK3QwC"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Block"
      ],
      "metadata": {
        "id": "0hxdHOHi8Dt-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dblock = DataBlock(blocks = (ImageBlock, MaskBlock(codes)),\n",
        "                  get_items = get_image_files,\n",
        "                  splitter = splitter,\n",
        "                  get_y = get_y_fn,\n",
        "                  item_tfms = item_tfms,\n",
        "                  batch_tfms = [Normalize.from_stats(*imagenet_stats)]\n",
        "                  )\n",
        "  \n",
        "dls = dblock.dataloaders(train_images, bs=bs, num_workers=0)"
      ],
      "metadata": {
        "id": "YKluVI_53ctJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dls.show_batch(cmap='binary_r', vmin=0, vmax=1)"
      ],
      "metadata": {
        "id": "RwqBZQuJ3t3m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-p1gckIrurS"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seed_everything()"
      ],
      "metadata": {
        "id": "S23XrNlh8WvP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learn = unet_learner(dls, arch, pretrained = pretrained, metrics = metrics, wd=wd,\n",
        "                    act_cls = act_cls, self_attention = self_attention)\n"
      ],
      "metadata": {
        "id": "CSmZMeoR3kEQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learn.summary()"
      ],
      "metadata": {
        "id": "usx3-8cI3ybt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learn.fit_one_cycle(epochs, lr, cbs=callbacksFitBeforeUnfreeze)"
      ],
      "metadata": {
        "id": "mkjZzqnh4FBJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learn.show_results(cmap='binary_r', vmin=0, vmax=1)"
      ],
      "metadata": {
        "id": "18QQ2p147OjH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"~~~~~~~~~~~~~~~~~~~~~~~~~Training Result~~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
        "learn.validate()"
      ],
      "metadata": {
        "id": "MeSHgjI-4Pyy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cze9h1XfbLJB"
      },
      "source": [
        "# Testing "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lkeh9fzfkaKN"
      },
      "outputs": [],
      "source": [
        "test_img = get_image_files(test_images)\n",
        "dl = learn.dls.test_dl(test_img, with_labels=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dl.show_batch(max_n=9, cmap='binary_r', vmin=0, vmax=1)"
      ],
      "metadata": {
        "id": "AUc5AwFy4ZIR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n6M_M0u_4uLt"
      },
      "outputs": [],
      "source": [
        "_,_,preds = learn.get_preds(dl=dl, with_decoded=true)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2vZIcnJx4uLt"
      },
      "outputs": [],
      "source": [
        "learn.show_results(dl=dl, shuffle=False, max_n=9, cmap='binary_r', vmin=0, vmax=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"~~~~~~~~~~~~~~~~~~~~~~~~~Testing Result~~~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
        "learn.validate(dl=dl)"
      ],
      "metadata": {
        "id": "rs8BklvL4Xi-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtuua6jV9dFB"
      },
      "source": [
        "# Export .pkl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eH_qXXc388_l"
      },
      "outputs": [],
      "source": [
        "learn.export()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEI0qR477tsT"
      },
      "source": [
        "# Upload .pth and .pkl to drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gupload --to '1IKUHdIiDgHPxeJt5gKhGmzrnxUJIAVG1' \"/content/models/Camonet_Best.pth\""
      ],
      "metadata": {
        "id": "Y6Zod4xf52Q8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gupload --to '1IKUHdIiDgHPxeJt5gKhGmzrnxUJIAVG1' \"/content/export.pkl\""
      ],
      "metadata": {
        "id": "UrtSf0zo9cNT"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "01U81VYgNCXo",
        "KgifIBJBdj2A",
        "m9zFwG9ibdAP",
        "yxK7bLUjuyob",
        "Gsbtw3nugokf",
        "q-p1gckIrurS",
        "QJTYIGecbYqP",
        "-GjHElnlRq0-",
        "HmdJeDdTo8RH",
        "t9AZm4EgIwwc",
        "Rmi6dXA2o8RL",
        "kVEZ8Ljyo8RL",
        "F9Wa6RoGpkrX",
        "jQqTX-N7I2ju",
        "RVSjrZ54pkrg",
        "HvRe6z14pkrh",
        "b7-jamiMpkrf",
        "3E4WT-SjCRBE",
        "RrtzACS-I9HL",
        "2AAz-Jd7CRBM",
        "pw7GE0KBCRBM",
        "cSdzsODgCRBL",
        "l3zOAUWqFWzz",
        "PNYFXQsTk0vg",
        "Y7EmiUrv0tuZ",
        "nWJOuSK40tuY",
        "RGTkLFuM0tuZ",
        "DAH_9Jh60tuQ",
        "kuNtShKf0tuZ",
        "4j66oassRPfl",
        "qmuX_I8XRPfm",
        "iv4fxpyeRPfn",
        "zgzyR0J8RPfn",
        "I9jTWAKvRPfo",
        "_Q4SQFEO1o_m",
        "aOg5nAfS1o_v",
        "nfqcBPDK1o_u",
        "Kko8JHHA1o_u",
        "H9sWgjCe1o_t",
        "eQp5gz2B1o_u",
        "lZvOQdGA1pOY",
        "pn8jcHwa1pOZ",
        "7fOQvp9x1pOY",
        "5UN3MK881pOZ",
        "IKPPJDQo1pOY",
        "LfuNRCeb1pOZ",
        "rZZZWwwn2t0M",
        "ZDJObX1yIBIr",
        "6HuH1wQoosL7",
        "v9ktmyrnot5Z",
        "RS8CiRcpovOz",
        "rzbNUB1LovuC",
        "KkG5W91X5s_O",
        "mYPWfMjvozL9",
        "hkdJNnie53GK",
        "i1-mc5Who0DG",
        "ns7WRkzg6A83",
        "bSd3Gaw_o09q",
        "CLjkGwFF6WAO",
        "ZcIpE04o6eku",
        "zfyKX4V06nIH",
        "wxVwu6IzpItY",
        "jzjOvAXipH7A",
        "DuX509IApJBA",
        "GIhL_bH8pJ15",
        "FIjmMk-n67-P",
        "R46iNqyUpKBx",
        "HQkAgbnw7Dos",
        "CD3uXkVBpK-N",
        "tcnDvg3dpLWZ",
        "rJIUIgi6pLys",
        "BnMptDLq7Q0T",
        "DCAC9_-OpMfu",
        "kwlzcwnbpMGC",
        "TCbOx7SZpNvE",
        "FiYnfEIc7THs",
        "kr5kWL-U7TX7",
        "GQvZ5CuM7VDM",
        "e-xcVfYspPB0",
        "zb7yRx1R7-CT",
        "i6oiAZTw8Dyz",
        "NVgymuXqpPX7",
        "-WWuMM3gWqqr",
        "SJh61LSZpXE3",
        "qhhU09BwpXlw",
        "owMO7zpcpYZ_",
        "PoP6_IzypYxA",
        "vH_6AOxSpY84",
        "6-8GoEz9pZOg",
        "TAUTchKZpZZQ",
        "QfzTs8rPpZlw",
        "MLRkO13epZ5A",
        "i7RvTeO6paEJ",
        "0_FtXvUspaYJ",
        "RvsGFpdtpaix",
        "kHFbjgkkpa0K",
        "e3brt4uspa9R",
        "o0Px4ETcpbRi",
        "k1-vaQanpb8h",
        "G5s2JJjqpcha",
        "8Ti5_Qp4pcqS",
        "AP8iA48EpdXi",
        "yEKinP9IpdjC",
        "HvVJJFaypd2q",
        "S4FDY-gQpeCb",
        "d_9hN2rTpeOC",
        "STcOps5ipeeD",
        "l35Uuc7w1I6n",
        "BkvVMHDd1I6l",
        "iqucdMaj1I6k",
        "09B_r6dvQvSB",
        "VwxAdI5t1I6k",
        "Ifz9U-wM1I6l",
        "N6D_TtLH1I6l",
        "ks_8ioyl1I6l",
        "4ZuQ9X0X1I6l",
        "gtuHtfQu1I6n",
        "RPvBARnc1I6n",
        "ult1B-pZ1I6r",
        "ItWtGXRh1I6r",
        "BBeAga7f1I6o",
        "knFcydat1I6o",
        "Tg0qKioc1I6q",
        "WVru7sUW1I6q",
        "ehyuXQon1I6q",
        "wgYo6x8H1I6r",
        "7Q4QrgVg1I6r",
        "qo8AVp8w1I6r",
        "3d_HxSJ296HX",
        "j2-UUwjV96HV",
        "K1umyDk-96HU",
        "o1gjiWKg96HV",
        "IUGlWUT396HV",
        "90aYeGib96HW",
        "fE0vNux096HW",
        "PiFh1jno96HW",
        "feQDmcOJ96HW",
        "TxqWeZvy96HX",
        "TNYu-Ul696Hd",
        "xYw3U37U96He",
        "0eGyy0Bw96HZ",
        "aSJ-1aR896HZ",
        "GL5ZMeH_96Hc",
        "tkTLwSoI96Hc",
        "ZifAJwEd96Hd",
        "a0eEavzb96Hd",
        "5AyCiTOR96Hd",
        "tOgLErYX96Ha",
        "qJtggysE96Hl",
        "8lqKkniw96Hf",
        "MZI6gM7D96Hg",
        "-Xr2tAzQ96Hg",
        "1Zhw4W_u96Hk",
        "OtEFrdVY96Hk",
        "VLCZ26kN96Hk",
        "7Zp-gp4f96Hk",
        "5BoRgK6gZRFH",
        "skKAAUmR96Hq",
        "O9jIoq0696Hm",
        "5zklW2T596Hn",
        "DwCX_dkY96Hp",
        "cS4eWJXC96Hp",
        "jzKKFhgn96Hp",
        "DEOA8jX796Hp",
        "egT5BxqO96Hp",
        "pKZtS3OC96Hq",
        "jXee3D_C96Ho",
        "ourntmmM96Hv",
        "nKO0er_r96Ht",
        "oaS661W996Hs",
        "wLvD4O4hRHCu",
        "1vbbWWV396Ht",
        "T9B0K87Q96Ht",
        "WrkwqVLP96Hu",
        "Xs2e5kAy96Hu",
        "rmfbPAxD96Hu",
        "y2dAnpGE96Hu",
        "DCkSPpqS96Hv",
        "oYc8Lgfz96Hw",
        "uAow33Rd96Hz",
        "lusbdrVv96Hz",
        "dbyOpDcT96Hw",
        "FK_CFKJ596Hw",
        "fE5h5PK696Hy",
        "UKuR79kq96Hy",
        "waLr7SXa96Hz",
        "sbxzALYa96Hz",
        "ZJLWJn9g96Hz",
        "zm4jC_X796Hz",
        "SkPEwlvJ96Hy",
        "GAQar-hLdYZn",
        "Rbr-zWVn5V_i",
        "5HQo9E_rq_ek",
        "gEhV3Ni45bFB",
        "F8YWZZ_YTnsN",
        "R72ydZ0Q6_Q4",
        "x0YYeiUc7LBL",
        "v7F1OsTn7K6w",
        "sUBjAOAa7PcJ",
        "0rNx2ofw7PcK",
        "cze9h1XfbLJB",
        "jtuua6jV9dFB",
        "KEI0qR477tsT"
      ],
      "name": "best.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}